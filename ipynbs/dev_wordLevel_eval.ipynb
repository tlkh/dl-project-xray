{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(\"..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/krishna/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torchvision import transforms\n",
    "import apex\n",
    "import csv\n",
    "import models\n",
    "import ast\n",
    "from sklearn.model_selection import train_test_split\n",
    "from fastprogress.fastprogress import master_bar, progress_bar\n",
    "from tqdm.auto import trange\n",
    "\n",
    "from config import config\n",
    "import dataset_word as data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_list(input_str):    \n",
    "    return ast.literal_eval(input_str)\n",
    "\n",
    "reports = {}\n",
    "\n",
    "with open(config.cleaned_reports) as csv_file:\n",
    "    csv_reader = csv.reader(csv_file, delimiter=',')\n",
    "    line_count = 0\n",
    "    for row in csv_reader:\n",
    "        if line_count == 0:\n",
    "            line_count += 1\n",
    "        else:\n",
    "            uid, problems, findings, impression = row[1:]\n",
    "            reports[str(uid)] = (parse_list(problems), findings, impression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_report_splits(reports, seed=1337):\n",
    "    uid_list = list(reports.keys())\n",
    "    train_uids, valtest_uids = train_test_split(uid_list, test_size=0.2, random_state=seed)\n",
    "    valid_uids, test_uids = train_test_split(valtest_uids, test_size=0.5, random_state=seed)\n",
    "\n",
    "    train_reports = {}\n",
    "    valid_reports = {}\n",
    "    test_reports = {}\n",
    "    splits = [train_uids, valid_uids, test_uids]\n",
    "    output_reports = [train_reports, valid_reports, test_reports]\n",
    "    \n",
    "    for i in range(len(splits)):\n",
    "        for uid in splits[i]:\n",
    "            output_reports[i][str(uid)] = reports[str(uid)]\n",
    "            \n",
    "    return output_reports\n",
    "\n",
    "train_reports, valid_reports, _ = create_report_splits(reports)\n",
    "IMAGE_SIZE = 768\n",
    "\n",
    "train_dataset = data.XRayDataset(\n",
    "    reports=train_reports,\n",
    "    transform=transforms.Compose([\n",
    "        transforms.Resize(IMAGE_SIZE),\n",
    "        transforms.CenterCrop((IMAGE_SIZE,IMAGE_SIZE)),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                             std=[0.229, 0.224, 0.225]),\n",
    "    ]\n",
    "))\n",
    "train_dataloader = torch.utils.data.dataloader.DataLoader(train_dataset,\n",
    "                                                          collate_fn=data.collate_fn,\n",
    "                                                          pin_memory=True,\n",
    "                                                          shuffle=True,\n",
    "                                                          batch_size=config.batch_size,\n",
    "                                                          num_workers=config.batch_size)\n",
    "\n",
    "valid_dataset = data.XRayDataset(\n",
    "    reports=valid_reports,\n",
    "    transform=transforms.Compose([\n",
    "        transforms.Resize(IMAGE_SIZE),\n",
    "        transforms.CenterCrop((IMAGE_SIZE,IMAGE_SIZE)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                             std=[0.229, 0.224, 0.225]),\n",
    "        ]\n",
    "))\n",
    "valid_dataloader = torch.utils.data.dataloader.DataLoader(valid_dataset,\n",
    "                                                          collate_fn=data.collate_fn,\n",
    "                                                          pin_memory=True,\n",
    "                                                          shuffle=True,\n",
    "                                                          batch_size=config.batch_size,\n",
    "                                                          num_workers=config.batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embeddings: 1946 x 300\n",
      "Loading embedding file: ./vectors/glove.6B.300d.txt\n",
      "Pre-trained: 1611 (82.79%)\n",
      "Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.\n",
      "\n",
      "Defaults for this optimization level are:\n",
      "enabled                : True\n",
      "opt_level              : O1\n",
      "cast_model_type        : None\n",
      "patch_torch_functions  : True\n",
      "keep_batchnorm_fp32    : None\n",
      "master_weights         : None\n",
      "loss_scale             : dynamic\n",
      "Processing user overrides (additional kwargs that are not None)...\n",
      "After processing overrides, optimization options are:\n",
      "enabled                : True\n",
      "opt_level              : O1\n",
      "cast_model_type        : None\n",
      "patch_torch_functions  : True\n",
      "keep_batchnorm_fp32    : None\n",
      "master_weights         : None\n",
      "loss_scale             : dynamic\n"
     ]
    }
   ],
   "source": [
    "memory_format = torch.channels_last\n",
    "num_classes = len(train_dataset.classes)\n",
    "\n",
    "encoder = models.EncoderCNN(config.emb_dim, num_classes).to(config.device, memory_format=memory_format)\n",
    "decoder = models.DecoderRNN_Word(config.emb_dim, config.hidden_dim, train_dataset.tokenizer, config.num_layers).to(config.device, memory_format=memory_format)\n",
    "\n",
    "classes_loss = torch.nn.BCEWithLogitsLoss()\n",
    "outputs_loss = torch.nn.CrossEntropyLoss()\n",
    "params = list(decoder.parameters()) + list(encoder.parameters())\n",
    "optimizer = apex.optimizers.FusedAdam(params, lr=config.learning_rate)\n",
    "\n",
    "[encoder, decoder], optimizer = apex.amp.initialize([encoder, decoder], optimizer, opt_level=\"O1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(dataloader, batch_size, encoder, decoder, classes_loss, outputs_loss, optimizer, train=True):\n",
    "    total_step = len(dataloader.dataset)//batch_size\n",
    "    if train:\n",
    "        encoder.train()\n",
    "        decoder.train()\n",
    "    else:\n",
    "        encoder.eval()\n",
    "        decoder.eval()\n",
    "    running_c_loss = torch.Tensor([0.0])\n",
    "    running_o_loss = torch.Tensor([0.0])\n",
    "    state_h, state_c = decoder.zero_state(batch_size)\n",
    "    state_h = state_h.to(config.device, non_blocking=True)\n",
    "    state_c = state_c.to(config.device, non_blocking=True)\n",
    "    with torch.set_grad_enabled(train):\n",
    "        for i, (images, class_labels, captions, lengths) in enumerate(progress_bar(dataloader)):\n",
    "            images = images.to(config.device, non_blocking=True).contiguous(memory_format=memory_format)\n",
    "            captions = captions.to(config.device, non_blocking=True)\n",
    "            class_labels = class_labels.to(config.device, non_blocking=True)\n",
    "            targets = torch.nn.utils.rnn.pack_padded_sequence(captions, lengths, batch_first=True, enforce_sorted=False)[0]\n",
    "            encoder.zero_grad()\n",
    "            decoder.zero_grad()\n",
    "            logits, features = encoder(images)\n",
    "            c_loss = classes_loss(logits, class_labels)\n",
    "            outputs, (state_h, state_c) = decoder(features, captions, lengths, (state_h, state_c))\n",
    "            o_loss = outputs_loss(outputs, targets)\n",
    "            if train:\n",
    "                with apex.amp.scale_loss(c_loss, optimizer) as scaled_loss:\n",
    "                    scaled_loss.backward(retain_graph=True)\n",
    "                with apex.amp.scale_loss(o_loss, optimizer) as scaled_loss:\n",
    "                    scaled_loss.backward()\n",
    "                state_h = state_h.detach()\n",
    "                state_c = state_c.detach()\n",
    "                optimizer.step()\n",
    "            running_c_loss += c_loss\n",
    "            running_o_loss += o_loss\n",
    "            if train and i % 10 == 0:\n",
    "                print(\n",
    "                    \"train_loss - \",\n",
    "                    round(float(c_loss.cpu().detach().numpy()), 3),\n",
    "                    round(float(o_loss.cpu().detach().numpy()), 3),\n",
    "                    \"- perplexity -\",\n",
    "                    round(float(np.exp(o_loss.cpu().detach().numpy())), 3),\n",
    "                )\n",
    "    c_loss = float(running_c_loss.item() / total_step)\n",
    "    o_loss = float(running_o_loss.item() / total_step)\n",
    "    return c_loss, o_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Uncomment below code to train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# num_epochs = 5\n",
    "# print(\"Start training\")\n",
    "\n",
    "# for epoch in range(num_epochs):\n",
    "#     print(\"\\nEpoch\", epoch+1, \"/\", num_epochs, \":\\n\")\n",
    "#     train_c_loss, train_o_loss = train_one_epoch(train_dataloader, config.batch_size, encoder, decoder, classes_loss, outputs_loss, optimizer, train=True)\n",
    "#     valid_c_loss, valid_o_loss = train_one_epoch(valid_dataloader, config.batch_size, encoder, decoder, classes_loss, outputs_loss, optimizer, train=False)\n",
    "#     print(\"train_loss - \", round(train_c_loss,3),round(train_o_loss,3), \"- perplexity -\", round(np.exp(train_o_loss),3),\n",
    "#           \"- valid_loss - \", round(valid_c_loss,3),round(valid_o_loss,3), \"- perplexity -\", round(np.exp(valid_o_loss),3))\n",
    "# print(\"Finished training!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save / Load trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# torch.save(encoder.state_dict(), 'save/encoder_word.pt')\n",
    "# torch.save(decoder.state_dict(), 'save/decoder_word.pt')\n",
    "encoder.load_state_dict(torch.load('save/encoder_word.pt'))\n",
    "decoder.load_state_dict(torch.load('save/decoder_word.pt'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Average Precision over class logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running inference...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e6355b2189a740478affb0e1b5299941",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, layout=Layout(flex='2'), max=330.0), HTML(value='')), layout=Layout(diâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from evaluate import get_class_predictions\n",
    "y_true, y_pred = get_class_predictions(encoder, valid_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  4.   0.   0.  19.   0.   0.  40.   2. 184.   6.  67.   0.   0.   0.\n",
      "   0.   0.   0.   0.   0.   0.   0.   0.   0.  44.   0. 312.  29.   0.\n",
      "   0. 284. 293.   0. 316.  75.   0. 182.  13.   0.  14.   0.   0.   0.\n",
      "   0.   0.  13.   0.  58.  18.]\n",
      "\n",
      "\n",
      "Recall\n",
      "[0.    0.    0.    0.    0.    0.    0.075 0.    0.136 0.167 0.09  0.\n",
      " 0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.045\n",
      " 0.    0.154 0.069 0.    0.    0.44  0.113 0.    0.123 0.08  0.    0.115\n",
      " 0.077 0.    0.    0.    0.    0.    0.    0.    0.077 0.    0.069 0.167]\n",
      "\n",
      "\n",
      "Precision\n",
      "[0.    0.    0.    0.    0.    0.    0.158 0.    0.893 0.1   0.545 0.\n",
      " 0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.5\n",
      " 0.    1.    0.2   0.    0.    0.962 1.    0.    1.    0.75  0.    0.913\n",
      " 0.2   0.    0.    0.    0.    0.    0.    0.    0.111 0.    0.16  0.429]\n",
      "\n",
      "\n",
      "AP\n",
      "[0.042 0.03  0.009 0.03  0.006 0.067 0.06  0.018 0.13  0.044 0.064 0.006\n",
      " 0.024 0.024 0.024 0.052 0.009 0.012 0.021 0.018 0.012 0.009 0.009 0.029\n",
      " 0.006 0.154 0.038 0.018 0.012 0.438 0.113 0.024 0.123 0.066 0.006 0.111\n",
      " 0.028 0.009 0.003 0.012 0.027 0.033 0.024 0.015 0.033 0.012 0.075 0.084]\n",
      "\n",
      "\n",
      "mean AP\n",
      "0.046\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda/miniconda3/envs/ai/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from evaluate import evaluate_encoder_predictions\n",
    "recall, precision, AP, mAP = evaluate_encoder_predictions(y_true, y_pred)\n",
    "print(\"\\n\\nRecall\")\n",
    "print(recall.round(3))\n",
    "print(\"\\n\\nPrecision\")\n",
    "print(precision.round(3))\n",
    "print(\"\\n\\nAP\")\n",
    "print(AP.round(3))\n",
    "print(\"\\n\\nmean AP\")\n",
    "print(mAP.round(3))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
